{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeJTzAT-U3fj"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Thought process:\n",
        "\n",
        "1. The code begins by setting up Kaggle API credentials, which are necessary to download the dataset from Kaggle.\n",
        "\n",
        "2. It then downloads and extracts the NYC Yellow Taxi Trip dataset using the Kaggle CLI.\n",
        "\n",
        "3. Dask is installed and imported along with other necessary libraries. Dask is used because it's efficient for handling large datasets that may not fit into memory.\n",
        "\n",
        "4. The dataset is loaded using Dask's read_csv function, which can handle multiple CSV files at once.\n",
        "\n",
        "5. The coordinates of the Crate and Barrel store are defined.\n",
        "\n",
        "6. A function `is_near_crate_and_barrel` is created to check if a dropoff location is near the Crate and Barrel store. It uses numpy's `isclose` function to allow for some tolerance in the coordinate matching.\n",
        "\n",
        "7. This function is applied to the dataframe to create a new boolean column 'near_crate_and_barrel'.\n",
        "\n",
        "8. The dataframe is then filtered to include only the trips near Crate and Barrel.\n",
        "\n",
        "9. Pickup and dropoff times are converted to datetime objects for easier manipulation.\n",
        "\n",
        "10. Hour and minute are extracted from the dropoff time and added as new columns.\n",
        "\n",
        "11. The final dataframe is computed (this is necessary with Dask to actually perform the operations).\n",
        "\n",
        "12. Finally, the processed data is saved to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiREgeBJWDq6",
        "outputId": "205e15eb-e842-4b47-95a6-8393c515cca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data\n",
            "License(s): U.S. Government Works\n",
            "Downloading nyc-yellow-taxi-trip-data.zip to /content\n",
            "100% 1.78G/1.78G [00:18<00:00, 137MB/s]\n",
            "100% 1.78G/1.78G [00:18<00:00, 101MB/s]\n",
            "Archive:  nyc-yellow-taxi-trip-data.zip\n",
            "  inflating: data/yellow_tripdata_2015-01.csv  \n",
            "  inflating: data/yellow_tripdata_2016-01.csv  \n",
            "  inflating: data/yellow_tripdata_2016-02.csv  \n",
            "  inflating: data/yellow_tripdata_2016-03.csv  \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d elemento/nyc-yellow-taxi-trip-data\n",
        "!unzip nyc-yellow-taxi-trip-data.zip -d data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YkjXsAZz8dyM",
        "outputId": "868870c2-b314-41df-9341-65018b992b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2023.8.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (24.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.19.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dask\n",
        "# Install and import required libraries\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset using Dask\n",
        "df = dd.read_csv('data/yellow_tripdata_*.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sal3-w2R9jGj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "crate_and_barrel_coords = (-73.974785, 40.750618)\n",
        "# Define the coordinates of Crate and Barrel store\n",
        "def is_near_crate_and_barrel(row):\n",
        "    return np.isclose(row['dropoff_longitude'], crate_and_barrel_coords[0], atol=0.001) and np.isclose(row['dropoff_latitude'], crate_and_barrel_coords[1], atol=0.001)\n",
        "# Apply the function to create a new column 'near_crate_and_barrel'\n",
        "df['near_crate_and_barrel'] = df.apply(is_near_crate_and_barrel, axis=1, meta=('near_crate_and_barrel', 'bool'))\n",
        "# Filter the dataframe to include only trips near Crate and Barrel\n",
        "filtered_df = df[df['near_crate_and_barrel']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKbQ_qSn9p5L"
      },
      "outputs": [],
      "source": [
        "df['tpep_pickup_datetime'] = dd.to_datetime(df['tpep_pickup_datetime'])\n",
        "df['tpep_dropoff_datetime'] = dd.to_datetime(df['tpep_dropoff_datetime'])\n",
        "df['dropoff_hour'] = df['tpep_dropoff_datetime'].dt.hour\n",
        "df['dropoff_minute'] = df['tpep_dropoff_datetime'].dt.minute\n",
        "\n",
        "# Compute the filtered dataframe\n",
        "df = df.compute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZpFarGcQ79s"
      },
      "outputs": [],
      "source": [
        "df.to_csv('final_filtered_data.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
